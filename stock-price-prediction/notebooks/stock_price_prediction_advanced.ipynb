{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "618ccd38",
   "metadata": {},
   "source": [
    "# Advanced Stock Price Prediction\n",
    "\n",
    "This notebook implements an advanced stock price prediction project suitable for a resume/GitHub. It includes data download, EDA, feature engineering (MA, EMA, RSI), classical ML (Linear Regression, Random Forest), LSTM deep learning, hyperparameter tuning, multi-step forecasting, evaluation, and instructions for saving and pushing the project to GitHub.\n",
    "\n",
    "**Notes:**\n",
    "- This notebook is intended to be run locally. It uses `yfinance` to download data. If you run this in an environment without internet access, first download the CSV into `data/` and adjust the data path.\n",
    "- Cells marked `ðŸš€` are key steps for training and evaluation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e516dd0",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3260636281.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[8], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    pip install --quiet yfinance pandas numpy matplotlib scikit-learn tensorflow keras seaborn ta\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Setup: install required packages (run in your environment once)\n",
    "%%bash\n",
    "pip install --quiet yfinance pandas numpy matplotlib scikit-learn tensorflow keras seaborn ta\n",
    "echo 'Packages installed (or already present).'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fecff1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "from sklearn.model_selection import train_test_split, TimeSeriesSplit, GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "sns.set(style='darkgrid')\n",
    "\n",
    "print('Imports ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e977b74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "TICKER = 'AAPL'  # change as needed\n",
    "START_DATE = '2015-01-01'\n",
    "END_DATE = datetime.today().strftime('%Y-%m-%d')\n",
    "WINDOW = 60  # sequence length for LSTM\n",
    "FUTURE_DAYS = 7  # multi-step forecast horizon\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "\n",
    "os.makedirs('data', exist_ok=True)\n",
    "os.makedirs('model', exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a84d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download historical data using yfinance\n",
    "import yfinance as yf\n",
    "\n",
    "csv_path = f'data/{TICKER}.csv'\n",
    "if not os.path.exists(csv_path):\n",
    "    df = yf.download(TICKER, start=START_DATE, end=END_DATE)\n",
    "    df.to_csv(csv_path)\n",
    "    print('Downloaded to', csv_path)\n",
    "else:\n",
    "    df = pd.read_csv(csv_path, index_col=0, parse_dates=True)\n",
    "    print('Loaded existing CSV:', csv_path)\n",
    "\n",
    "# show head\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48950e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic EDA\n",
    "print('Shape:', df.shape)\n",
    "print(df.info())\n",
    "\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.plot(df['Close'])\n",
    "plt.title(f'{TICKER} Close Price')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Close Price')\n",
    "plt.show()\n",
    "\n",
    "# Daily returns\n",
    "if 'Adj Close' in df.columns:\n",
    "    df['Return'] = df['Adj Close'].pct_change()\n",
    "else:\n",
    "    df['Return'] = df['Close'].pct_change()\n",
    "\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.plot(df['Return'].fillna(0))\n",
    "plt.title('Daily Returns')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37a75b0",
   "metadata": {},
   "source": [
    "## Feature engineering\n",
    "We will add commonly-used technical indicators: moving averages (MA), exponential moving averages (EMA), and RSI. You can add more indicators from the `ta` package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35045140",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature engineering functions\n",
    "\n",
    "def add_technical_indicators(df):\n",
    "    df = df.copy()\n",
    "    df['MA10'] = df['Close'].rolling(window=10).mean()\n",
    "    df['MA21'] = df['Close'].rolling(window=21).mean()\n",
    "    df['EMA10'] = df['Close'].ewm(span=10, adjust=False).mean()\n",
    "    df['EMA21'] = df['Close'].ewm(span=21, adjust=False).mean()\n",
    "    # RSI\n",
    "    delta = df['Close'].diff()\n",
    "    up = delta.clip(lower=0)\n",
    "    down = -1 * delta.clip(upper=0)\n",
    "    roll_up = up.rolling(14).mean()\n",
    "    roll_down = down.rolling(14).mean()\n",
    "    rs = roll_up / roll_down\n",
    "    df['RSI'] = 100.0 - (100.0 / (1.0 + rs))\n",
    "    # Volatility (rolling std of returns)\n",
    "    df['Volatility'] = df['Return'].rolling(window=21).std()\n",
    "    df = df.fillna(method='bfill').fillna(method='ffill')\n",
    "    return df\n",
    "\n",
    "# apply\n",
    "if 'Return' not in df.columns:\n",
    "    df['Return'] = df['Close'].pct_change()\n",
    "\n",
    "df = add_technical_indicators(df)\n",
    "print(df[['Close','MA10','MA21','EMA10','EMA21','RSI','Volatility']].tail())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17808e56",
   "metadata": {},
   "source": [
    "### Prepare supervised dataset for classical ML models\n",
    "We will use lag features (previous n days' close) and the technical indicators to train Linear Regression and Random Forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb08f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lag features\n",
    "LAGS = 5\n",
    "\n",
    "feat_df = df.copy()\n",
    "for lag in range(1, LAGS+1):\n",
    "    feat_df[f'lag_{lag}'] = feat_df['Close'].shift(lag)\n",
    "\n",
    "# target: next-day Close\n",
    "feat_df['target'] = feat_df['Close'].shift(-1)\n",
    "feat_df = feat_df.dropna()\n",
    "\n",
    "features = [f'lag_{i}' for i in range(1, LAGS+1)] + ['MA10','MA21','EMA10','EMA21','RSI','Volatility']\n",
    "X = feat_df[features]\n",
    "y = feat_df['target']\n",
    "\n",
    "print('Feature columns:', X.columns.tolist())\n",
    "print('Shapes', X.shape, y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddbd9f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time-series split (train/test) - keep chronological order\n",
    "split_idx = int(len(X)*0.8)\n",
    "X_train, X_test = X.iloc[:split_idx], X.iloc[split_idx:]\n",
    "y_train, y_test = y.iloc[:split_idx], y.iloc[split_idx:]\n",
    "\n",
    "print('Train size:', X_train.shape, 'Test size:', X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95cdd358",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline: Linear Regression\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "y_pred_lr = lr.predict(X_test)\n",
    "\n",
    "mse_lr = mean_squared_error(y_test, y_pred_lr)\n",
    "mae_lr = mean_absolute_error(y_test, y_pred_lr)\n",
    "r2_lr = r2_score(y_test, y_pred_lr)\n",
    "\n",
    "print('Linear Regression - MSE:', mse_lr, 'MAE:', mae_lr, 'R2:', r2_lr)\n",
    "\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.plot(y_test.values, label='Actual')\n",
    "plt.plot(y_pred_lr, label='LR Predicted')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c836cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest: quick hyperparameter search\n",
    "rf = RandomForestRegressor(random_state=SEED)\n",
    "params = {'n_estimators':[50,100], 'max_depth':[5,10,None]}\n",
    "\n",
    "# Use small grid for speed; expand for serious tuning\n",
    "gcv = GridSearchCV(rf, params, cv=3, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "gcv.fit(X_train, y_train)\n",
    "print('Best params:', gcv.best_params_)\n",
    "\n",
    "best_rf = gcv.best_estimator_\n",
    "rf_pred = best_rf.predict(X_test)\n",
    "\n",
    "mse_rf = mean_squared_error(y_test, rf_pred)\n",
    "mae_rf = mean_absolute_error(y_test, rf_pred)\n",
    "r2_rf = r2_score(y_test, rf_pred)\n",
    "\n",
    "print('Random Forest - MSE:', mse_rf, 'MAE:', mae_rf, 'R2:', r2_rf)\n",
    "\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.plot(y_test.values, label='Actual')\n",
    "plt.plot(rf_pred, label='RF Predicted')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f537189",
   "metadata": {},
   "source": [
    "## Prepare data for LSTM\n",
    "We'll use the `Close` price scaled with MinMaxScaler and create sequences of length `WINDOW`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44537dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM data preparation using Close price\n",
    "close_vals = df[['Close']].values\n",
    "scaler = MinMaxScaler()\n",
    "close_scaled = scaler.fit_transform(close_vals)\n",
    "\n",
    "# create sequences\n",
    "def create_sequences(data, window=60):\n",
    "    Xs, ys = [], []\n",
    "    for i in range(window, len(data)):\n",
    "        Xs.append(data[i-window:i, 0])\n",
    "        ys.append(data[i, 0])\n",
    "    return np.array(Xs), np.array(ys)\n",
    "\n",
    "X_seq, y_seq = create_sequences(close_scaled, WINDOW)\n",
    "\n",
    "# split chronologically\n",
    "split_idx_seq = int(len(X_seq)*0.8)\n",
    "X_train_seq, X_test_seq = X_seq[:split_idx_seq], X_seq[split_idx_seq:]\n",
    "y_train_seq, y_test_seq = y_seq[:split_idx_seq], y_seq[split_idx_seq:]\n",
    "\n",
    "# reshape for LSTM\n",
    "X_train_seq = X_train_seq.reshape((X_train_seq.shape[0], X_train_seq.shape[1], 1))\n",
    "X_test_seq = X_test_seq.reshape((X_test_seq.shape[0], X_test_seq.shape[1], 1))\n",
    "\n",
    "print('LSTM shapes', X_train_seq.shape, X_test_seq.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff9d89a",
   "metadata": {},
   "source": [
    "### Build and train LSTM model\n",
    "We use a 2-layer LSTM with Dropout and EarlyStopping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e1e777",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build LSTM\n",
    "model = Sequential([\n",
    "    LSTM(64, return_sequences=True, input_shape=(WINDOW,1)),\n",
    "    Dropout(0.2),\n",
    "    LSTM(32),\n",
    "    Dropout(0.2),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "model.summary()\n",
    "\n",
    "# Callbacks\n",
    "es = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "mc = ModelCheckpoint('model/lstm_best.h5', monitor='val_loss', save_best_only=True)\n",
    "\n",
    "# Train (you can increase epochs)\n",
    "history = model.fit(X_train_seq, y_train_seq, epochs=30, batch_size=32,\n",
    "                    validation_data=(X_test_seq, y_test_seq), callbacks=[es, mc])\n",
    "\n",
    "# Plot loss\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='val')\n",
    "plt.legend()\n",
    "plt.title('LSTM training loss')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e94d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM predictions and inverse transform\n",
    "lstm_pred_scaled = model.predict(X_test_seq)\n",
    "\n",
    "# inverse transform\n",
    "lstm_pred = scaler.inverse_transform(lstm_pred_scaled)\n",
    "y_test_actual = scaler.inverse_transform(y_test_seq.reshape(-1,1))\n",
    "\n",
    "mse_lstm = mean_squared_error(y_test_actual, lstm_pred)\n",
    "mae_lstm = mean_absolute_error(y_test_actual, lstm_pred)\n",
    "r2_lstm = r2_score(y_test_actual, lstm_pred)\n",
    "\n",
    "print('LSTM - MSE:', mse_lstm, 'MAE:', mae_lstm, 'R2:', r2_lstm)\n",
    "\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.plot(y_test_actual, label='Actual')\n",
    "plt.plot(lstm_pred, label='LSTM Predicted')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d4338b",
   "metadata": {},
   "source": [
    "## Multi-step Forecast (next N days)\n",
    "We will use the trained LSTM to forecast the next `FUTURE_DAYS` by iteratively feeding back predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4e9b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-step forecast using last WINDOW days\n",
    "\n",
    "def multi_step_forecast(model, recent_window, scaler, future_days=7):\n",
    "    # recent_window: array of shape (WINDOW,)\n",
    "    preds = []\n",
    "    current_seq = recent_window.copy()\n",
    "    for _ in range(future_days):\n",
    "        x = current_seq.reshape((1, current_seq.shape[0], 1))\n",
    "        pred_scaled = model.predict(x)[0,0]\n",
    "        preds.append(pred_scaled)\n",
    "        # append and slide\n",
    "        current_seq = np.append(current_seq[1:], pred_scaled)\n",
    "    # inverse transform\n",
    "    preds = np.array(preds).reshape(-1,1)\n",
    "    preds_inv = scaler.inverse_transform(preds)\n",
    "    return preds_inv.flatten()\n",
    "\n",
    "# get recent window\n",
    "recent_window = close_scaled[-WINDOW:].reshape(-1)\n",
    "future_preds = multi_step_forecast(model, recent_window, scaler, FUTURE_DAYS)\n",
    "print('Next', FUTURE_DAYS, 'day predictions (LSTM):')\n",
    "print(future_preds)\n",
    "\n",
    "# visualize\n",
    "future_dates = [df.index[-1] + timedelta(days=i+1) for i in range(FUTURE_DAYS)]\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.plot(df.index[-200:], df['Close'].tail(200), label='Recent Actual')\n",
    "plt.plot(future_dates, future_preds, marker='o', linestyle='--', label='Forecast')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b40152",
   "metadata": {},
   "source": [
    "## Compare models (summary)\n",
    "We'll summarize metrics for Linear Regression, Random Forest, and LSTM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef841a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate metrics\n",
    "results = pd.DataFrame({\n",
    "    'Model': ['LinearRegression','RandomForest','LSTM'],\n",
    "    'MSE': [mse_lr, mse_rf, mse_lstm],\n",
    "    'MAE': [mae_lr, mae_rf, mae_lstm],\n",
    "    'R2': [r2_lr, r2_rf, r2_lstm]\n",
    "})\n",
    "results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3450efc6",
   "metadata": {},
   "source": [
    "## Save models and artifacts\n",
    "Save trained models, scalers, and example plots for the GitHub repo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740d171f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Save sklearn models\n",
    "joblib.dump(lr, 'model/linear_regression.pkl')\n",
    "joblib.dump(best_rf, 'model/random_forest.pkl')\n",
    "# Save scaler for LSTM\n",
    "joblib.dump(scaler, 'model/close_scaler.pkl')\n",
    "\n",
    "print('Saved model artifacts to model/ (linear_regression.pkl, random_forest.pkl, close_scaler.pkl, lstm_best.h5)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91eb68ff",
   "metadata": {},
   "source": [
    "## Project structure & Git commands\n",
    "\n",
    "Add these files to your GitHub repo and push:\n",
    "\n",
    "```\n",
    "stock-price-prediction-advanced/\n",
    "â”œâ”€â”€ data/                 # CSVs (do NOT push large raw data if you have many files)\n",
    "â”œâ”€â”€ model/                # saved models\n",
    "â”œâ”€â”€ notebooks/            # this notebook\n",
    "â”œâ”€â”€ src/                  # helper scripts (download, preprocess, train, predict)\n",
    "â”œâ”€â”€ streamlit_app/        # optional: streamlit app for demo\n",
    "â”œâ”€â”€ requirements.txt\n",
    "â””â”€â”€ README.md\n",
    "```\n",
    "\n",
    "Example git commands:\n",
    "\n",
    "```bash\n",
    "git init\n",
    "git add .\n",
    "git commit -m \"Initial commit: advanced stock price prediction notebook\"\n",
    "git branch -M main\n",
    "git remote add origin https://github.com/<your-username>/stock-price-prediction-advanced.git\n",
    "git push -u origin main\n",
    "```\n",
    "\n",
    "Add screenshots & brief summary to README.md, and include instructions to run the notebook and reproduce results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d40af7",
   "metadata": {},
   "source": [
    "## Final tips to make it resume-ready\n",
    "- Add a concise README with project goal, tech stack, how to run, and results.\n",
    "- Include screenshots of plots and the Streamlit app (if you add one).\n",
    "- Add a small `requirements.txt` and instructions to create a `venv`.\n",
    "- Provide a short demo video/GIF in the repo if possible.\n",
    "\n",
    "---\n",
    "\n",
    "You're ready to run this notebook locally. Good luck!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
